# Observability Stack - Microservice d'Ingestion

Une solution complÃ¨te de monitoring et d'observabilitÃ© pour microservices d'ingestion de donnÃ©es, conforme aux spÃ©cifications de l'exercice Grafana Pipeline avec Kafka, Prometheus, Loki et Grafana.

## ğŸ¯ **Vue d'ensemble du Projet**

Ce projet implÃ©mente une solution complÃ¨te d'observabilitÃ© pour microservices d'ingestion, conforme aux spÃ©cifications du document `exercice_grafana_pipeline.md`. Il traite les logs d'exÃ©cution d'APIs (Zoho, PowerBI, Efficy, SharePoint, EasyProjects) et les transforme en mÃ©triques et visualisations pour Grafana.

### **CaractÃ©ristiques ClÃ©s**
- **Producer Python** qui lit logs.json et publie sur topic `ingestion-logs`
- **Consumer Python** qui traite les Ã©vÃ©nements Kafka et gÃ©nÃ¨re des mÃ©triques
- **Dashboard Grafana** suivant les spÃ©cifications _MConverter avec terminologie franÃ§aise
- **6 rÃ¨gles d'alertes** (Ã©chec, taux d'Ã©chec, source muette, latence dÃ©gradÃ©e, etc.)
- **Architecture Docker** prÃªte pour production

## ğŸ—ï¸ **Architecture**

```mermaid
graph TB
    subgraph "DonnÃ©es"
        JSON[logs.json]
    end

    subgraph "Traitement Kafka"
        PROD[Producer Python]
        KAFKA[Apache Kafka]
        CONS[Consumer Python]
    end

    subgraph "ObservabilitÃ©"
        PROM[Prometheus]
        LOKI[Loki]
        GRAF[Grafana]
    end

    subgraph "Management"
        KUI[Kafka UI]
        PROMTAIL[Promtail]
    end

    JSON --> PROD
    PROD --> KAFKA
    KAFKA --> CONS
    CONS --> PROM
    CONS --> LOKI
    PROMTAIL --> LOKI
    PROM --> GRAF
    LOKI --> GRAF
    KAFKA --> KUI
```

### Composants

| Service | Port | Description |
|---------|------|-------------|
| **Producer** | - | Script producer.py qui lit logs.json et publie sur topic ingestion-logs |
| **Consumer** | 8000 | Traitement: consomme Kafka, parse JSON, dÃ©finit labels, pousse vers Loki |
| **Kafka** | 9092 | Message broker pour le streaming des logs |
| **Zookeeper** | 2181 | Coordination pour Kafka |
| **Prometheus** | 9090 | Collecte et stockage des mÃ©triques |
| **Loki** | 3100 | Collecte et stockage des logs pour Grafana |
| **Grafana** | 3000 | Tableau de bord selon spÃ©cifications _MConverter |
| **Kafka UI** | 8080 | Interface de gestion Kafka |

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
- Docker et Docker Compose
- 8GB RAM minimum
- Ports 3000, 3100, 8080, 9090, 9092 disponibles

### Installation

1. **DÃ©marrer la stack complÃ¨te**
```bash
docker-compose up -d
```

2. **VÃ©rifier le statut des services**
```bash
docker-compose ps
```

3. **ExÃ©cuter le producer pour traiter logs.json**
```bash
# Le producer se lance automatiquement
# Ou manuellement:
docker-compose run --rm producer python producer.py
```

### AccÃ¨s aux Interfaces
- **Grafana**: http://localhost:3000 (admin/admin123)
- **Prometheus**: http://localhost:9090
- **Kafka UI**: http://localhost:8080
- **Loki**: http://localhost:3100

## ğŸ“Š Dashboard Grafana

Le dashboard suit exactement les spÃ©cifications du document `_MConverter.eu_dashboard_grafana_ingestion.md` :

### 1) Vue d'ensemble --- Ingestion: Health
- **Statuts derniÃ¨re exÃ©cution**: SuccÃ¨s (N), Ã‰checs (N), Taux d'Ã©chec (%)
- **p95 durÃ©e (s)** et **Max mÃ©moire (MB)**
- **Timeline des runs** (barre empilÃ©e par Ã‰tat)
- **Top sources par durÃ©e** (p95)

### 2) FiabilitÃ© --- Errors & SLAs
- **Taux d'Ã©chec** global et par Source
- **MTTR** (Mean Time To Recovery)
- **SLO de fraÃ®cheur**: alerte si pas de run > X minutes

### 3) Performance --- Latency & Throughput
- **DurÃ©es**: p50/p95/p99 de Duree secondes par Source et Objet
- **DÃ©bit**: nb d'exÃ©cutions / 5 min par Source
- **CPU & mÃ©moire**: p95 par Source

### 4) DÃ©tails par connecteur --- Sources & Objets
- **Grille filtrable** avec colonnes: Debut, Fin, Duree secondes, cpu_time, memory_used, Description

### 5) Derniers messages d'erreur
- **Table des 5 derniers FAILED** avec dÃ©tails

### 6) Exemple de visuel du dashboard
- Panel Type Stat: SuccÃ¨s=120, Ã‰checs=3
- Taux d'Ã©chec Stat (%): 2.4 %
- DurÃ©e (p95) Time series: 2.3s
- DerniÃ¨res erreurs Table: Source=A, Objet=X, Desc=timeout

## ğŸš¨ RÃ¨gles d'Alertes

ConformÃ©ment aux spÃ©cifications, les 6 rÃ¨gles d'alerte suivantes sont implÃ©mentÃ©es :

### 1. Ã‰chec dÃ©tectÃ© (critique)
- **Condition**: >0 FAILED sur 5 minutes
- **Seuil**: ImmÃ©diat
- **SÃ©vÃ©ritÃ©**: Critical

### 2. Taux d'Ã©chec Ã©levÃ©
- **Condition**: >2% pendant 15 minutes
- **Seuil**: 2%
- **SÃ©vÃ©ritÃ©**: Warning

### 3. Source muette
- **Condition**: pas d'occurrence sur 75 minutes
- **Seuil**: 75 minutes
- **SÃ©vÃ©ritÃ©**: Warning

### 4. Latence p95 dÃ©gradÃ©e
- **Condition**: p95 > 2Ã— baseline (60s)
- **Seuil**: 60 secondes
- **SÃ©vÃ©ritÃ©**: Warning

### 5. Surconsommation mÃ©moire/CPU
- **MÃ©moire**: >150 MB (p95)
- **CPU**: >60s (p95)
- **SÃ©vÃ©ritÃ©**: Warning

### 6. Burst d'erreurs sur un Objet
- **Condition**: >3 erreurs sur 10 minutes
- **Seuil**: 3 erreurs
- **SÃ©vÃ©ritÃ©**: Warning

## ğŸ”§ Configuration

### Variables d'Environnement

#### Producer
```env
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=ingestion-logs
LOGS_FILE_PATH=/app/data/logs.json
LOG_LEVEL=INFO
SIMULATE_REALTIME=false
```

#### Consumer
```env
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=ingestion-logs
KAFKA_GROUP_ID=ingestion-consumer-group
LOKI_URL=http://loki:3100
METRICS_PORT=8000
LOG_LEVEL=INFO
```

### Structure JSON AmÃ©liorÃ©e

Le producer transforme les logs originaux en structure optimisÃ©e pour l'observabilitÃ© :

```json
{
  "@timestamp": "2025-09-15T10:30:00.000Z",
  "@version": "1",
  "event": {
    "dataset": "ingestion-logs",
    "kind": "event",
    "outcome": "success"
  },
  "source": {
    "name": "PowerBI",
    "type": "api"
  },
  "objet": {
    "id": 1224,
    "name": "workspaces",
    "transformation": "PowerBI_API_get_data"
  },
  "etat": "SUCCESS",
  "performance": {
    "duree_secondes": 1.154133,
    "cpu_time_sec": 0.11,
    "memory_used_bytes": 5849088,
    "memory_used_mb": 5.58
  },
  "labels": {
    "etat": "SUCCESS",
    "source": "PowerBI",
    "zone": "1-Raw",
    "entreprise": "akonovia"
  },
  "metrics": {
    "is_failed": 0,
    "is_success": 1,
    "high_memory_usage": 0,
    "high_cpu_usage": 0
  }
}
```

## ğŸ” Monitoring et Debugging

### VÃ©rifier les Logs
```bash
# Producer
docker-compose logs -f producer

# Consumer
docker-compose logs -f consumer

# Tous les services
docker-compose logs -f
```

### VÃ©rifier les MÃ©triques
```bash
# MÃ©triques Prometheus du consumer
curl http://localhost:8000/metrics

# Statut Prometheus
curl http://localhost:9090/-/healthy

# Statut Loki
curl http://localhost:3100/ready
```

### Kafka Management
```bash
# Lister les topics
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# DÃ©crire le topic ingestion-logs
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic ingestion-logs

# Consumer group status
docker-compose exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group ingestion-consumer-group
```

## ğŸ§ª Tests et Validation

### Test du Producer
```bash
# ExÃ©cuter le producer une fois
docker-compose run --rm producer python producer.py

# Mode simulation temps rÃ©el
docker-compose run --rm -e SIMULATE_REALTIME=true producer python producer.py
```

### Validation des MÃ©triques
```bash
# VÃ©rifier que les mÃ©triques sont collectÃ©es
curl -s http://localhost:9090/api/v1/query?query=ingestion_runs_total | jq

# VÃ©rifier les logs dans Loki
curl -s "http://localhost:3100/loki/api/v1/query_range?query={job=\"ingestion-logs\"}&start=$(date -d '1 hour ago' --iso-8601)&end=$(date --iso-8601)" | jq
```

### Test des Alertes

1. **Simuler des Ã©checs**: Modifier les logs pour inclure des Ã©tats FAILED
2. **VÃ©rifier dans Grafana**: Aller dans Alerting > Alert Rules
3. **Tester une source muette**: ArrÃªter le producer et attendre 75 minutes

## ğŸ“ Structure du Projet

```
observability-stack/
â”œâ”€â”€ docker-compose.yml              # Configuration Docker Compose
â”œâ”€â”€ logs.json                       # DonnÃ©es d'exemple d'ingestion
â”œâ”€â”€ README.md                       # Documentation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producer/
â”‚   â”‚   â”œâ”€â”€ producer.py             # Script producer Kafka
â”‚   â”‚   â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”‚   â”‚   â””â”€â”€ Dockerfile              # Image Docker producer
â”‚   â””â”€â”€ consumer/
â”‚       â”œâ”€â”€ consumer.py             # Script consumer avec mÃ©triques
â”‚       â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”‚       â””â”€â”€ Dockerfile              # Image Docker consumer
â””â”€â”€ config/
    â”œâ”€â”€ prometheus/
    â”‚   â”œâ”€â”€ prometheus.yml          # Configuration Prometheus
    â”‚   â””â”€â”€ alerts/
    â”‚       â””â”€â”€ ingestion-alerts.yml # RÃ¨gles d'alertes
    â”œâ”€â”€ loki/
    â”‚   â””â”€â”€ loki-config.yml         # Configuration Loki
    â”œâ”€â”€ promtail/
    â”‚   â””â”€â”€ promtail-config.yml     # Configuration Promtail
    â””â”€â”€ grafana/
        â”œâ”€â”€ provisioning/
        â”‚   â”œâ”€â”€ datasources/
        â”‚   â”‚   â””â”€â”€ datasources.yml # Configuration datasources
        â”‚   â””â”€â”€ dashboards/
        â”‚       â””â”€â”€ dashboards.yml  # Configuration dashboards
        â””â”€â”€ dashboards/
            â””â”€â”€ dashboard-grafana-ingestion.json # Dashboard principal
```

## ğŸ”„ Production Readiness

### SÃ©curitÃ©
- [ ] Configurer l'authentification Grafana (LDAP/OAuth)
- [ ] SÃ©curiser Kafka avec SSL/SASL
- [ ] Utiliser des secrets Docker pour les mots de passe
- [ ] Configurer les certificats TLS

### ScalabilitÃ©
- [ ] Augmenter les partitions Kafka pour parallÃ©lisme
- [ ] DÃ©ployer plusieurs instances consumer
- [ ] Configurer la rÃ©plication Kafka
- [ ] Utiliser un stockage persistant (S3, GCS)

### Backup et Recovery
- [ ] Sauvegarder les configurations Grafana
- [ ] Configurer la rÃ©tention des donnÃ©es Prometheus/Loki
- [ ] Planifier les sauvegardes des topics Kafka
- [ ] Documenter les procÃ©dures de recovery

## ğŸ› ï¸ DÃ©pannage

### ProblÃ¨mes Courants

#### Services qui ne dÃ©marrent pas
```bash
# VÃ©rifier les logs
docker-compose logs <service_name>

# RedÃ©marrer un service
docker-compose restart <service_name>

# Reconstruire les images
docker-compose build --no-cache
```

#### Kafka Connection Issues
```bash
# VÃ©rifier la connectivitÃ© Kafka
docker-compose exec producer python -c "from kafka import KafkaProducer; print('OK')"

# VÃ©rifier les topics
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list
```

#### MÃ©triques manquantes
```bash
# VÃ©rifier l'endpoint du consumer
curl http://localhost:8000/metrics

# VÃ©rifier la configuration Prometheus
curl http://localhost:9090/api/v1/targets
```

#### Dashboard vide
1. VÃ©rifier que les datasources sont connectÃ©es
2. VÃ©rifier que les mÃ©triques remontent dans Prometheus
3. VÃ©rifier les labels dans les requÃªtes PromQL

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. Consulter les logs avec `docker-compose logs`
2. VÃ©rifier la documentation des composants
3. Ouvrir une issue avec les logs et la configuration

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.