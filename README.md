# Observability Stack - Microservice d'Ingestion

Une solution compl√®te de monitoring et d'observabilit√© pour microservices d'ingestion de donn√©es, conforme aux sp√©cifications de l'exercice Grafana Pipeline avec Kafka, Prometheus, Loki et Grafana.

## üéØ **Vue d'ensemble du Projet**

Ce projet impl√©mente une solution compl√®te d'observabilit√© pour microservices d'ingestion, conforme aux sp√©cifications du document `exercice_grafana_pipeline.md`. Il traite les logs d'ex√©cution d'APIs (Zoho, PowerBI, Efficy, SharePoint, EasyProjects) et les transforme en m√©triques et visualisations pour Grafana.

### **Caract√©ristiques Cl√©s**
- **Producer Python** qui lit logs.json et publie sur topic `ingestion-logs`
- **Consumer Python** qui traite les √©v√©nements Kafka et g√©n√®re des m√©triques
- **Dashboard Grafana** suivant les sp√©cifications _MConverter avec terminologie fran√ßaise
- **6 r√®gles d'alertes** (√©chec, taux d'√©chec, source muette, latence d√©grad√©e, etc.)
- **Architecture Docker** pr√™te pour production

## üèóÔ∏è **Architecture**

```mermaid
graph TB
    subgraph "Donn√©es"
        JSON[logs.json]
    end

    subgraph "Traitement Kafka"
        PROD[Producer Python]
        KAFKA[Apache Kafka]
        CONS[Consumer Python]
    end

    subgraph "Observabilit√©"
        PROM[Prometheus]
        LOKI[Loki]
        GRAF[Grafana]
    end

    subgraph "Management"
        KUI[Kafka UI]
        PROMTAIL[Promtail]
    end

    JSON --> PROD
    PROD --> KAFKA
    KAFKA --> CONS
    CONS --> PROM
    CONS --> LOKI
    PROMTAIL --> LOKI
    PROM --> GRAF
    LOKI --> GRAF
    KAFKA --> KUI
```

### Composants

| Service | Port | Description |
|---------|------|-------------|
| **Producer** | - | Script producer.py qui lit logs.json et publie sur topic ingestion-logs |
| **Consumer** | 8000 | Traitement: consomme Kafka, parse JSON, d√©finit labels, pousse vers Loki |
| **Kafka** | 9092 | Message broker pour le streaming des logs |
| **Zookeeper** | 2181 | Coordination pour Kafka |
| **Prometheus** | 9090 | Collecte et stockage des m√©triques |
| **Loki** | 3100 | Collecte et stockage des logs pour Grafana |
| **Grafana** | 3000 | Tableau de bord selon sp√©cifications _MConverter |
| **Kafka UI** | 8080 | Interface de gestion Kafka |

## üöÄ D√©marrage Rapide

### Pr√©requis
- Docker et Docker Compose
- 8GB RAM minimum
- Ports 3000, 3100, 8080, 9090, 9092 disponibles

### Installation

1. **D√©marrer la stack compl√®te**
```bash
docker-compose up -d
```

2. **V√©rifier le statut des services**
```bash
docker-compose ps
```

3. **Ex√©cuter le producer pour traiter logs.json**
```bash
# Le producer se lance automatiquement
# Ou manuellement:
docker-compose run --rm producer python producer.py
```

### Acc√®s aux Interfaces
- **Grafana**: http://localhost:3000 (admin/admin123)
- **Prometheus**: http://localhost:9090
- **Kafka UI**: http://localhost:8080
- **Loki**: http://localhost:3100

## üìä Dashboard Grafana

Le dashboard suit exactement les sp√©cifications du document `_MConverter.eu_dashboard_grafana_ingestion.md` :

### 1) Vue d'ensemble --- Ingestion: Health
- **Statuts derni√®re ex√©cution**: Succ√®s (N), √âchecs (N), Taux d'√©chec (%)
- **p95 dur√©e (s)** et **Max m√©moire (MB)**
- **Timeline des runs** (barre empil√©e par √âtat)
- **Top sources par dur√©e** (p95)

### 2) Fiabilit√© --- Errors & SLAs
- **Taux d'√©chec** global et par Source
- **MTTR** (Mean Time To Recovery)
- **SLO de fra√Æcheur**: alerte si pas de run > X minutes

### 3) Performance --- Latency & Throughput
- **Dur√©es**: p50/p95/p99 de Duree secondes par Source et Objet
- **D√©bit**: nb d'ex√©cutions / 5 min par Source
- **CPU & m√©moire**: p95 par Source

### 4) D√©tails par connecteur --- Sources & Objets
- **Grille filtrable** avec colonnes: Debut, Fin, Duree secondes, cpu_time, memory_used, Description

### 5) Derniers messages d'erreur
- **Table des 5 derniers FAILED** avec d√©tails

### 6) Exemple de visuel du dashboard
- Panel Type Stat: Succ√®s=120, √âchecs=3
- Taux d'√©chec Stat (%): 2.4 %
- Dur√©e (p95) Time series: 2.3s
- Derni√®res erreurs Table: Source=A, Objet=X, Desc=timeout

## üö® R√®gles d'Alertes

Conform√©ment aux sp√©cifications, les 6 r√®gles d'alerte suivantes sont impl√©ment√©es :

### 1. √âchec d√©tect√© (critique)
- **Condition**: >0 FAILED sur 5 minutes
- **Seuil**: Imm√©diat
- **S√©v√©rit√©**: Critical

### 2. Taux d'√©chec √©lev√©
- **Condition**: >2% pendant 15 minutes
- **Seuil**: 2%
- **S√©v√©rit√©**: Warning

### 3. Source muette
- **Condition**: pas d'occurrence sur 75 minutes
- **Seuil**: 75 minutes
- **S√©v√©rit√©**: Warning

### 4. Latence p95 d√©grad√©e
- **Condition**: p95 > 2√ó baseline (60s)
- **Seuil**: 60 secondes
- **S√©v√©rit√©**: Warning

### 5. Surconsommation m√©moire/CPU
- **M√©moire**: >150 MB (p95)
- **CPU**: >60s (p95)
- **S√©v√©rit√©**: Warning

### 6. Burst d'erreurs sur un Objet
- **Condition**: >3 erreurs sur 10 minutes
- **Seuil**: 3 erreurs
- **S√©v√©rit√©**: Warning

## üîß Configuration

### Variables d'Environnement

#### Producer
```env
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=ingestion-logs
LOGS_FILE_PATH=/app/data/logs.json
LOG_LEVEL=INFO
SIMULATE_REALTIME=false
```

#### Consumer
```env
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=ingestion-logs
KAFKA_GROUP_ID=ingestion-consumer-group
LOKI_URL=http://loki:3100
METRICS_PORT=8000
LOG_LEVEL=INFO
```

### Structure JSON Am√©lior√©e

Le producer transforme les logs originaux en structure optimis√©e pour l'observabilit√© :

```json
{
  "@timestamp": "2025-09-15T10:30:00.000Z",
  "@version": "1",
  "event": {
    "dataset": "ingestion-logs",
    "kind": "event",
    "outcome": "success"
  },
  "source": {
    "name": "PowerBI",
    "type": "api"
  },
  "objet": {
    "id": 1224,
    "name": "workspaces",
    "transformation": "PowerBI_API_get_data"
  },
  "etat": "SUCCESS",
  "performance": {
    "duree_secondes": 1.154133,
    "cpu_time_sec": 0.11,
    "memory_used_bytes": 5849088,
    "memory_used_mb": 5.58
  },
  "labels": {
    "etat": "SUCCESS",
    "source": "PowerBI",
    "zone": "1-Raw",
    "entreprise": "akonovia"
  },
  "metrics": {
    "is_failed": 0,
    "is_success": 1,
    "high_memory_usage": 0,
    "high_cpu_usage": 0
  }
}
```

## üìä M√©triques Disponibles

Le consumer g√©n√®re automatiquement les m√©triques suivantes pour Prometheus :

### M√©triques Core d'Ingestion

#### `ingestion_runs_total` (Counter)
Nombre total d'ex√©cutions d'ingestion par √©tat
```
ingestion_runs_total{source="PowerBI",etat="SUCCESS",objet="workspaces",entreprise="akonovia",zone="1-Raw"}
ingestion_runs_total{source="sharepoint_graph",etat="FAILED",objet="EventFactureApplication",entreprise="akonovia",zone="1-Raw"}
```

#### `ingestion_duration_seconds` (Histogram)
Distribution des dur√©es d'ex√©cution
```
ingestion_duration_seconds_bucket{source="Efficy",objet="Contact",le="0.5"}
ingestion_duration_seconds_bucket{source="Efficy",objet="Contact",le="1.0"}
ingestion_duration_seconds_sum{source="Efficy",objet="Contact"}
ingestion_duration_seconds_count{source="Efficy",objet="Contact"}
```

#### `ingestion_cpu_usage_seconds` (Histogram)
Distribution de l'utilisation CPU
```
ingestion_cpu_usage_seconds_bucket{source="EasyProjects",objet="Projects",le="0.1"}
ingestion_cpu_usage_seconds_bucket{source="EasyProjects",objet="Projects",le="0.5"}
```

#### `ingestion_memory_usage_bytes` (Histogram)
Distribution de l'utilisation m√©moire
```
ingestion_memory_usage_bytes_bucket{source="zohobooks",objet="invoices_ga",le="1.048576e+06"}
ingestion_memory_usage_bytes_bucket{source="zohobooks",objet="invoices_ga",le="5.24288e+06"}
```

#### `ingestion_last_run_timestamp` (Gauge)
Timestamp de la derni√®re ex√©cution par source
```
ingestion_last_run_timestamp{source="PowerBI"}
ingestion_last_run_timestamp{source="Efficy"}
```

#### `ingestion_failures_total` (Counter)
Nombre total d'√©checs par source et objet
```
ingestion_failures_total{source="sharepoint_graph",objet="EventFactureApplication"}
```

### Labels Standards

Toutes les m√©triques incluent les labels suivants :
- `source` : Syst√®me source (PowerBI, Efficy, SharePoint, etc.)
- `etat` : √âtat de l'ex√©cution (SUCCESS/FAILED)
- `objet` : Type d'objet trait√©
- `entreprise` : Identifiant entreprise (akonovia)
- `zone` : Zone de processing (1-Raw)

### M√©triques Syst√®me Kafka

#### `kafka_consumer_lag_sum`
Retard du consumer Kafka sur le topic ingestion-logs
```
kafka_consumer_lag_sum{topic="ingestion-logs"}
```

## üß™ Guide de Test √âtape par √âtape

### **√âtape 1 : V√©rification Initiale**

1. **Cloner et d√©marrer la stack**
```bash
git clone <repository>
cd observability-stack
docker-compose up -d
```

2. **Attendre le d√©marrage complet (60 secondes)**
```bash
sleep 60
```

3. **V√©rifier que tous les services sont UP**
```bash
docker-compose ps
# Tous les services doivent √™tre "Up" ou "healthy"
```

### **√âtape 2 : Test des Endpoints de Sant√©**

```bash
# Test Prometheus
curl -s http://localhost:9090/-/healthy
# Doit retourner: "Prometheus Server is Healthy."

# Test Loki
curl -s http://localhost:3100/ready
# Doit retourner un message de ready ou "Ingester not ready: waiting for 15s after being ready"

# Test Grafana
curl -s http://localhost:3000/api/health | jq
# Doit retourner: {"commit":"895fbafb7a","database":"ok","version":"10.2.0"}

# Test Consumer (m√©triques endpoint)
curl -s http://localhost:8000/health || echo "Consumer endpoint pas encore expos√©"
```

### **√âtape 3 : Ingestion de Donn√©es**

1. **Ex√©cuter le producer pour ing√©rer les logs**
```bash
docker-compose --profile tools run --rm producer python producer.py
```

R√©sultat attendu :
```
2025-09-15 11:09:24,766 - __main__ - INFO - Charg√© 72 entr√©es de log depuis /app/data/logs.json
...
2025-09-15 11:09:25,000 - __main__ - INFO - Producteur termin√©: 72 succ√®s, 0 erreurs
```

2. **V√©rifier que le consumer traite les messages**
```bash
docker-compose logs consumer --tail=10
```

### **√âtape 4 : V√©rification des M√©triques**

1. **V√©rifier les m√©triques dans Prometheus**
```bash
# V√©rifier les m√©triques d'ingestion
curl -s "http://localhost:9090/api/v1/query?query=ingestion_runs_total" | jq '.data.result | length'
# Doit retourner un nombre > 0 (typiquement 72)

# V√©rifier les √©checs d√©tect√©s
curl -s "http://localhost:9090/api/v1/query?query=ingestion_runs_total{etat=\"FAILED\"}" | jq '.data.result | length'
# Doit retourner 1 (EventFactureApplication en FAILED)

# V√©rifier les succ√®s
curl -s "http://localhost:9090/api/v1/query?query=ingestion_runs_total{etat=\"SUCCESS\"}" | jq '.data.result | length'
# Doit retourner 71
```

2. **V√©rifier les dur√©es d'ex√©cution**
```bash
curl -s "http://localhost:9090/api/v1/query?query=ingestion_duration_seconds_sum" | jq '.data.result | length'
# Doit retourner le nombre de combinaisons source/objet uniques
```

3. **V√©rifier les m√©triques de performance**
```bash
# M√©triques CPU
curl -s "http://localhost:9090/api/v1/query?query=ingestion_cpu_usage_seconds_sum" | jq '.data.result'

# M√©triques M√©moire
curl -s "http://localhost:9090/api/v1/query?query=ingestion_memory_usage_bytes_sum" | jq '.data.result'
```

### **√âtape 5 : Test du Dashboard Grafana**

1. **Acc√©der √† Grafana**
```bash
# Ouvrir dans le navigateur
xdg-open http://localhost:3000  # Linux
open http://localhost:3000      # MacOS
start http://localhost:3000     # Windows
```

Identifiants : `admin` / `admin123`

2. **V√©rifier le Dashboard**
- Aller dans **Dashboards** > **Dashboard Grafana Ingestion**
- V√©rifier que les 5 sections sont pr√©sentes :
  - Vue d'ensemble --- Ingestion: Health
  - Fiabilit√© --- Errors & SLAs
  - Performance --- Latency & Throughput
  - D√©tails par connecteur --- Sources & Objets
  - Derniers messages d'erreur

3. **V√©rifier les donn√©es dans les panneaux**
```
- Succ√®s : devrait afficher 71
- √âchecs : devrait afficher 1
- Taux d'√©chec : devrait afficher ~1.4%
- Sources actives : PowerBI, Efficy, SharePoint, etc.
```

### **√âtape 6 : Test des Alertes**

1. **V√©rifier que les r√®gles d'alerte sont charg√©es**
```bash
curl -s "http://localhost:9090/api/v1/rules" | jq '.data.groups[].rules[] | select(.type=="alerting") | .name'
```

R√©sultat attendu :
```
"IngestionEchecDetecte"
"IngestionTauxEchecEleve"
"IngestionSourceMuette"
"IngestionLatenceDegradee"
"IngestionSurconsommationMemoire"
"IngestionSurconsommationCPU"
"IngestionBurstErreurs"
"IngestionConsumerDown"
"IngestionKafkaLag"
```

2. **V√©rifier l'√©tat des alertes**
```bash
curl -s "http://localhost:9090/api/v1/alerts" | jq '.data.alerts[] | {alert: .labels.alertname, state: .state}'
```

### **√âtape 7 : Test des Logs dans Loki**

1. **V√©rifier que les logs arrivent dans Loki**
```bash
# Query simple
curl -s "http://localhost:3100/loki/api/v1/query?query={job=\"ingestion-logs\"}&limit=5" | jq '.data.result | length'
# Doit retourner > 0

# Query avec filtre sur les √©checs
curl -s "http://localhost:3100/loki/api/v1/query?query={job=\"ingestion-logs\"} |= \"FAILED\"&limit=1" | jq '.data.result[0].values[0][1]'
```

### **√âtape 8 : Test de Performance**

1. **Test d'ingestion multiple**
```bash
# Ex√©cuter le producer plusieurs fois
for i in {1..3}; do
  echo "Run $i"
  docker-compose --profile tools run --rm producer python producer.py
  sleep 10
done
```

2. **V√©rifier l'accumulation des m√©triques**
```bash
# V√©rifier que les totaux augmentent
curl -s "http://localhost:9090/api/v1/query?query=sum(ingestion_runs_total)" | jq '.data.result[0].value[1]'
# Devrait √™tre > 144 (72 x 2 runs minimum)
```

### **√âtape 9 : Test des Interfaces de Management**

1. **Kafka UI**
```bash
xdg-open http://localhost:8080  # V√©rifier les topics et messages
```

2. **M√©triques Consumer directement**
```bash
curl -s http://localhost:8000/metrics | grep ingestion_ | head -10
```

### **√âtape 10 : Test de R√©silience**

1. **Tester l'arr√™t/red√©marrage d'un service**
```bash
# Arr√™ter le consumer
docker-compose stop consumer

# Relancer le producer (messages vont s'accumuler dans Kafka)
docker-compose --profile tools run --rm producer python producer.py

# Red√©marrer le consumer
docker-compose start consumer

# V√©rifier que les messages en attente sont trait√©s
docker-compose logs consumer --tail=20
```

2. **V√©rifier la r√©cup√©ration des m√©triques**
```bash
# Les m√©triques devraient inclure les nouveaux messages
curl -s "http://localhost:9090/api/v1/query?query=sum(ingestion_runs_total)" | jq '.data.result[0].value[1]'
```

## üîç Monitoring et Debugging

### V√©rifier les Logs
```bash
# Producer
docker-compose logs -f producer

# Consumer
docker-compose logs -f consumer

# Tous les services
docker-compose logs -f
```

### V√©rifier les M√©triques
```bash
# M√©triques Prometheus du consumer
curl http://localhost:8000/metrics

# Statut Prometheus
curl http://localhost:9090/-/healthy

# Statut Loki
curl http://localhost:3100/ready
```

### Kafka Management
```bash
# Lister les topics
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# D√©crire le topic ingestion-logs
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic ingestion-logs

# Consumer group status
docker-compose exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group ingestion-consumer-group
```

## üß™ Tests et Validation

### Test du Producer
```bash
# Ex√©cuter le producer une fois
docker-compose run --rm producer python producer.py

# Mode simulation temps r√©el
docker-compose run --rm -e SIMULATE_REALTIME=true producer python producer.py
```

### Validation des M√©triques
```bash
# V√©rifier que les m√©triques sont collect√©es
curl -s http://localhost:9090/api/v1/query?query=ingestion_runs_total | jq

# V√©rifier les logs dans Loki
curl -s "http://localhost:3100/loki/api/v1/query_range?query={job=\"ingestion-logs\"}&start=$(date -d '1 hour ago' --iso-8601)&end=$(date --iso-8601)" | jq
```

### Test des Alertes

1. **Simuler des √©checs**: Modifier les logs pour inclure des √©tats FAILED
2. **V√©rifier dans Grafana**: Aller dans Alerting > Alert Rules
3. **Tester une source muette**: Arr√™ter le producer et attendre 75 minutes

## üìÅ Structure du Projet

```
observability-stack/
‚îú‚îÄ‚îÄ docker-compose.yml              # Configuration Docker Compose
‚îú‚îÄ‚îÄ logs.json                       # Donn√©es d'exemple d'ingestion
‚îú‚îÄ‚îÄ README.md                       # Documentation
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ producer/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ producer.py             # Script producer Kafka
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances Python
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile              # Image Docker producer
‚îÇ   ‚îî‚îÄ‚îÄ consumer/
‚îÇ       ‚îú‚îÄ‚îÄ consumer.py             # Script consumer avec m√©triques
‚îÇ       ‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances Python
‚îÇ       ‚îî‚îÄ‚îÄ Dockerfile              # Image Docker consumer
‚îî‚îÄ‚îÄ config/
    ‚îú‚îÄ‚îÄ prometheus/
    ‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml          # Configuration Prometheus
    ‚îÇ   ‚îî‚îÄ‚îÄ alerts/
    ‚îÇ       ‚îî‚îÄ‚îÄ ingestion-alerts.yml # R√®gles d'alertes
    ‚îú‚îÄ‚îÄ loki/
    ‚îÇ   ‚îî‚îÄ‚îÄ loki-config.yml         # Configuration Loki
    ‚îú‚îÄ‚îÄ promtail/
    ‚îÇ   ‚îî‚îÄ‚îÄ promtail-config.yml     # Configuration Promtail
    ‚îî‚îÄ‚îÄ grafana/
        ‚îú‚îÄ‚îÄ provisioning/
        ‚îÇ   ‚îú‚îÄ‚îÄ datasources/
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ datasources.yml # Configuration datasources
        ‚îÇ   ‚îî‚îÄ‚îÄ dashboards/
        ‚îÇ       ‚îî‚îÄ‚îÄ dashboards.yml  # Configuration dashboards
        ‚îî‚îÄ‚îÄ dashboards/
            ‚îî‚îÄ‚îÄ dashboard-grafana-ingestion.json # Dashboard principal
```

## üîÑ Production Readiness

### S√©curit√©
- [ ] Configurer l'authentification Grafana (LDAP/OAuth)
- [ ] S√©curiser Kafka avec SSL/SASL
- [ ] Utiliser des secrets Docker pour les mots de passe
- [ ] Configurer les certificats TLS

### Scalabilit√©
- [ ] Augmenter les partitions Kafka pour parall√©lisme
- [ ] D√©ployer plusieurs instances consumer
- [ ] Configurer la r√©plication Kafka
- [ ] Utiliser un stockage persistant (S3, GCS)

### Backup et Recovery
- [ ] Sauvegarder les configurations Grafana
- [ ] Configurer la r√©tention des donn√©es Prometheus/Loki
- [ ] Planifier les sauvegardes des topics Kafka
- [ ] Documenter les proc√©dures de recovery

## üõ†Ô∏è D√©pannage

### Probl√®mes Courants

#### Services qui ne d√©marrent pas
```bash
# V√©rifier les logs
docker-compose logs <service_name>

# Red√©marrer un service
docker-compose restart <service_name>

# Reconstruire les images
docker-compose build --no-cache
```

#### Kafka Connection Issues
```bash
# V√©rifier la connectivit√© Kafka
docker-compose exec producer python -c "from kafka import KafkaProducer; print('OK')"

# V√©rifier les topics
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list
```

#### M√©triques manquantes
```bash
# V√©rifier l'endpoint du consumer
curl http://localhost:8000/metrics

# V√©rifier la configuration Prometheus
curl http://localhost:9090/api/v1/targets
```

#### Dashboard vide
1. V√©rifier que les datasources sont connect√©es
2. V√©rifier que les m√©triques remontent dans Prometheus
3. V√©rifier les labels dans les requ√™tes PromQL

## ‚úÖ R√©sultats Attendus des Tests

Si tout fonctionne correctement, vous devriez obtenir :

### M√©triques Prometheus
```bash
# Nombre total de m√©triques ingestion_runs_total
curl -s "http://localhost:9090/api/v1/query?query=ingestion_runs_total" | jq '.data.result | length'
# R√©sultat: 72 (toutes les combinaisons source/objet/√©tat)

# Distribution des √©tats
curl -s "http://localhost:9090/api/v1/query?query=sum by (etat) (ingestion_runs_total)"
# R√©sultat: SUCCESS=71, FAILED=1
```

### Sources de Donn√©es Identifi√©es
- **PowerBI**: workspaces, datasets, dashboards, dataflows, etc.
- **Efficy**: Contact, Company, Project, Opportunity, etc.
- **SharePoint**: LignesFacturesApplication, EventFactureApplication, etc.
- **EasyProjects**: Projects, Activities, Users, etc.
- **ZohoBooks**: invoices_ga, invoices_on, items_ga, etc.

### Alertes Configur√©es
- 9 r√®gles d'alertes charg√©es et fonctionnelles
- 1 alerte qui devrait se d√©clencher : **IngestionEchecDetecte** (√† cause du FAILED)

### Dashboard Grafana
- 5 sections principales avec donn√©es
- Visualisations des m√©triques de performance
- Table des derniers √©checs avec 1 entr√©e

### Performance Baseline
- **Dur√©e moyenne**: ~1-3 secondes par ex√©cution
- **M√©moire moyenne**: 5-20 MB par ex√©cution
- **CPU moyen**: 0.1-0.5 secondes par ex√©cution
- **D√©bit**: 72 ex√©cutions en ~1 seconde

## üöÄ Commandes Utiles Make

Le projet inclut un Makefile pour simplifier les op√©rations :

```bash
# Voir toutes les commandes disponibles
make help

# D√©marrer la stack
make up

# V√©rifier la sant√© des services
make health

# Ing√©rer des donn√©es
make ingest

# Voir les m√©triques du consumer
make metrics

# Ouvrir les interfaces
make open-grafana
make open-kafka-ui

# Tests automatis√©s
make test-stack

# Nettoyage complet
make clean
```

## üìû Support

Pour toute question ou probl√®me :
1. Consulter les logs avec `docker-compose logs`
2. V√©rifier la documentation des composants
3. Ouvrir une issue avec les logs et la configuration

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de d√©tails.