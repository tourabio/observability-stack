# Observability Stack - Microservice d'Ingestion

Une solution complÃ¨te de monitoring et d'observabilitÃ© pour microservices d'ingestion de donnÃ©es, conforme aux spÃ©cifications de l'exercice Grafana Pipeline avec Kafka, Prometheus, Loki et Grafana.

## ğŸ¯ **Vue d'ensemble du Projet**

Ce projet implÃ©mente une solution complÃ¨te d'observabilitÃ© pour microservices d'ingestion, conforme aux spÃ©cifications du document `exercice_grafana_pipeline.md`. Il traite les logs d'exÃ©cution d'APIs (Zoho, PowerBI, Efficy, SharePoint, EasyProjects) et les transforme en mÃ©triques et visualisations pour Grafana.

### **CaractÃ©ristiques ClÃ©s**
- **Producer Python** qui lit logs.json et publie sur topic `ingestion-logs`
- **Consumer Python** qui traite les Ã©vÃ©nements Kafka et gÃ©nÃ¨re des mÃ©triques
- **Dashboard Grafana** suivant les spÃ©cifications _MConverter avec terminologie franÃ§aise
- **6 rÃ¨gles d'alertes** (Ã©chec, taux d'Ã©chec, source muette, latence dÃ©gradÃ©e, etc.)
- **Architecture Docker** prÃªte pour production

## ğŸ—ï¸ **Architecture**

```mermaid
graph TB
    subgraph "DonnÃ©es"
        JSON[logs.json]
    end

    subgraph "Traitement Kafka"
        PROD[Producer Python]
        KAFKA[Apache Kafka]
        CONS[Consumer Python]
    end

    subgraph "ObservabilitÃ©"
        PROM[Prometheus]
        LOKI[Loki]
        GRAF[Grafana]
    end

    subgraph "Management"
        KUI[Kafka UI]
        PROMTAIL[Promtail]
    end

    JSON --> PROD
    PROD --> KAFKA
    KAFKA --> CONS
    CONS --> PROM
    CONS --> LOKI
    PROMTAIL --> LOKI
    PROM --> GRAF
    LOKI --> GRAF
    KAFKA --> KUI
```

### Composants

| Service | Port | Description |
|---------|------|-------------|
| **Producer** | - | Script producer.py qui lit logs.json et publie sur topic ingestion-logs |
| **Consumer** | 8000 | Traitement: consomme Kafka, parse JSON, dÃ©finit labels, pousse vers Loki |
| **Kafka** | 9092 | Message broker pour le streaming des logs |
| **Zookeeper** | 2181 | Coordination pour Kafka |
| **Prometheus** | 9090 | Collecte et stockage des mÃ©triques |
| **Loki** | 3100 | Collecte et stockage des logs pour Grafana |
| **Grafana** | 3000 | Tableau de bord selon spÃ©cifications _MConverter |
| **Kafka UI** | 8080 | Interface de gestion Kafka |

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
- Docker et Docker Compose
- 8GB RAM minimum
- Ports 3000, 3100, 8080, 9090, 9092 disponibles

### Installation

1. **DÃ©marrer la stack complÃ¨te**
```bash
docker-compose up -d
```

2. **VÃ©rifier le statut des services**
```bash
docker-compose ps
```

3. **ExÃ©cuter le producer pour traiter logs.json**
```bash
# Le producer se lance automatiquement
# Ou manuellement:
docker-compose run --rm producer python producer.py
```

### AccÃ¨s aux Interfaces
- **Grafana**: http://localhost:3000 (admin/admin123)
- **Prometheus**: http://localhost:9090
- **Kafka UI**: http://localhost:8080
- **Loki**: http://localhost:3100

## ğŸ“Š Dashboard Grafana

Le dashboard suit exactement les spÃ©cifications du document `_MConverter.eu_dashboard_grafana_ingestion.md` :

### 1) Vue d'ensemble --- Ingestion: Health
- **Statuts derniÃ¨re exÃ©cution**: SuccÃ¨s (N), Ã‰checs (N), Taux d'Ã©chec (%)
- **p95 durÃ©e (s)** et **Max mÃ©moire (MB)**
- **Timeline des runs** (barre empilÃ©e par Ã‰tat)
- **Top sources par durÃ©e** (p95)

### 2) FiabilitÃ© --- Errors & SLAs
- **Taux d'Ã©chec** global et par Source
- **MTTR** (Mean Time To Recovery)
- **SLO de fraÃ®cheur**: alerte si pas de run > X minutes

### 3) Performance --- Latency & Throughput
- **DurÃ©es**: p50/p95/p99 de Duree secondes par Source et Objet
- **DÃ©bit**: nb d'exÃ©cutions / 5 min par Source
- **CPU & mÃ©moire**: p95 par Source

### 4) DÃ©tails par connecteur --- Sources & Objets
- **Grille filtrable** avec colonnes: Debut, Fin, Duree secondes, cpu_time, memory_used, Description

### 5) Derniers messages d'erreur
- **Table des 5 derniers FAILED** avec dÃ©tails

### 6) Exemple de visuel du dashboard
- Panel Type Stat: SuccÃ¨s=120, Ã‰checs=3
- Taux d'Ã©chec Stat (%): 2.4 %
- DurÃ©e (p95) Time series: 2.3s
- DerniÃ¨res erreurs Table: Source=A, Objet=X, Desc=timeout

## ğŸš¨ RÃ¨gles d'Alertes

ConformÃ©ment aux spÃ©cifications, les 6 rÃ¨gles d'alerte suivantes sont implÃ©mentÃ©es :

### 1. Ã‰chec dÃ©tectÃ© (critique)
- **Condition**: >0 FAILED sur 5 minutes
- **Seuil**: ImmÃ©diat
- **SÃ©vÃ©ritÃ©**: Critical

### 2. Taux d'Ã©chec Ã©levÃ©
- **Condition**: >2% pendant 15 minutes
- **Seuil**: 2%
- **SÃ©vÃ©ritÃ©**: Warning

### 3. Source muette
- **Condition**: pas d'occurrence sur 75 minutes
- **Seuil**: 75 minutes
- **SÃ©vÃ©ritÃ©**: Warning

### 4. Latence p95 dÃ©gradÃ©e
- **Condition**: p95 > 2Ã— baseline (60s)
- **Seuil**: 60 secondes
- **SÃ©vÃ©ritÃ©**: Warning

### 5. Surconsommation mÃ©moire/CPU
- **MÃ©moire**: >150 MB (p95)
- **CPU**: >60s (p95)
- **SÃ©vÃ©ritÃ©**: Warning

### 6. Burst d'erreurs sur un Objet
- **Condition**: >3 erreurs sur 10 minutes
- **Seuil**: 3 erreurs
- **SÃ©vÃ©ritÃ©**: Warning

## ğŸ”§ Configuration

### Variables d'Environnement

#### Producer
```env
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=ingestion-logs
LOGS_FILE_PATH=/app/data/logs.json
LOG_LEVEL=INFO
SIMULATE_REALTIME=false
```

#### Consumer
```env
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=ingestion-logs
KAFKA_GROUP_ID=ingestion-consumer-group
LOKI_URL=http://loki:3100
METRICS_PORT=8000
LOG_LEVEL=INFO
```

### Structure JSON AmÃ©liorÃ©e

Le producer transforme les logs originaux en structure optimisÃ©e pour l'observabilitÃ© :

```json
{
  "@timestamp": "2025-09-15T10:30:00.000Z",
  "@version": "1",
  "event": {
    "dataset": "ingestion-logs",
    "kind": "event",
    "outcome": "success"
  },
  "source": {
    "name": "PowerBI",
    "type": "api"
  },
  "objet": {
    "id": 1224,
    "name": "workspaces",
    "transformation": "PowerBI_API_get_data"
  },
  "etat": "SUCCESS",
  "performance": {
    "duree_secondes": 1.154133,
    "cpu_time_sec": 0.11,
    "memory_used_bytes": 5849088,
    "memory_used_mb": 5.58
  },
  "labels": {
    "etat": "SUCCESS",
    "source": "PowerBI",
    "zone": "1-Raw",
    "entreprise": "akonovia"
  },
  "metrics": {
    "is_failed": 0,
    "is_success": 1,
    "high_memory_usage": 0,
    "high_cpu_usage": 0
  }
}
```

## ğŸ“Š MÃ©triques Disponibles

Le consumer gÃ©nÃ¨re automatiquement les mÃ©triques suivantes pour Prometheus :

### MÃ©triques Core d'Ingestion

#### `ingestion_runs_total` (Counter)
Nombre total d'exÃ©cutions d'ingestion par Ã©tat
```
ingestion_runs_total{source="PowerBI",etat="SUCCESS",objet="workspaces",entreprise="akonovia",zone="1-Raw"}
ingestion_runs_total{source="sharepoint_graph",etat="FAILED",objet="EventFactureApplication",entreprise="akonovia",zone="1-Raw"}
```

#### `ingestion_duration_seconds` (Histogram)
Distribution des durÃ©es d'exÃ©cution
```
ingestion_duration_seconds_bucket{source="Efficy",objet="Contact",le="0.5"}
ingestion_duration_seconds_bucket{source="Efficy",objet="Contact",le="1.0"}
ingestion_duration_seconds_sum{source="Efficy",objet="Contact"}
ingestion_duration_seconds_count{source="Efficy",objet="Contact"}
```

#### `ingestion_cpu_usage_seconds` (Histogram)
Distribution de l'utilisation CPU
```
ingestion_cpu_usage_seconds_bucket{source="EasyProjects",objet="Projects",le="0.1"}
ingestion_cpu_usage_seconds_bucket{source="EasyProjects",objet="Projects",le="0.5"}
```

#### `ingestion_memory_usage_bytes` (Histogram)
Distribution de l'utilisation mÃ©moire
```
ingestion_memory_usage_bytes_bucket{source="zohobooks",objet="invoices_ga",le="1.048576e+06"}
ingestion_memory_usage_bytes_bucket{source="zohobooks",objet="invoices_ga",le="5.24288e+06"}
```

#### `ingestion_last_run_timestamp` (Gauge)
Timestamp de la derniÃ¨re exÃ©cution par source
```
ingestion_last_run_timestamp{source="PowerBI"}
ingestion_last_run_timestamp{source="Efficy"}
```

#### `ingestion_failures_total` (Counter)
Nombre total d'Ã©checs par source et objet
```
ingestion_failures_total{source="sharepoint_graph",objet="EventFactureApplication"}
```

### Labels Standards

Toutes les mÃ©triques incluent les labels suivants :
- `source` : SystÃ¨me source (PowerBI, Efficy, SharePoint, etc.)
- `etat` : Ã‰tat de l'exÃ©cution (SUCCESS/FAILED)
- `objet` : Type d'objet traitÃ©
- `entreprise` : Identifiant entreprise (akonovia)
- `zone` : Zone de processing (1-Raw)

### MÃ©triques SystÃ¨me Kafka

#### `kafka_consumer_lag_sum`
Retard du consumer Kafka sur le topic ingestion-logs
```
kafka_consumer_lag_sum{topic="ingestion-logs"}
```

## ğŸ§ª Guide de Test Ã‰tape par Ã‰tape

### **Ã‰tape 1 : VÃ©rification Initiale**

1. **Cloner et dÃ©marrer la stack**
```bash
git clone <repository>
cd observability-stack
docker-compose up -d
```

2. **Attendre le dÃ©marrage complet (60 secondes)**
```bash
sleep 60
```

3. **VÃ©rifier que tous les services sont UP**
```bash
docker-compose ps
# Tous les services doivent Ãªtre "Up" ou "healthy"
```

### **Ã‰tape 2 : Test des Endpoints de SantÃ©**

```bash
# Test Prometheus
curl -s http://localhost:9090/-/healthy
# Doit retourner: "Prometheus Server is Healthy."

# Test Loki
curl -s http://localhost:3100/ready
# Doit retourner un message de ready ou "Ingester not ready: waiting for 15s after being ready"

# Test Grafana
curl -s http://localhost:3000/api/health | jq
# Doit retourner: {"commit":"895fbafb7a","database":"ok","version":"10.2.0"}

# Test Consumer (mÃ©triques endpoint)
curl -s http://localhost:8000/health || echo "Consumer endpoint pas encore exposÃ©"
```

### **Ã‰tape 3 : Ingestion de DonnÃ©es**

1. **ExÃ©cuter le producer pour ingÃ©rer les logs**
```bash
docker-compose --profile tools run --rm producer python producer.py
```

RÃ©sultat attendu :
```
2025-09-15 11:09:24,766 - __main__ - INFO - ChargÃ© 72 entrÃ©es de log depuis /app/data/logs.json
...
2025-09-15 11:09:25,000 - __main__ - INFO - Producteur terminÃ©: 72 succÃ¨s, 0 erreurs
```

2. **VÃ©rifier que le consumer traite les messages**
```bash
docker-compose logs consumer --tail=10
```

### **Ã‰tape 4 : VÃ©rification des MÃ©triques**

1. **VÃ©rifier les mÃ©triques dans Prometheus**
```bash
# VÃ©rifier les mÃ©triques d'ingestion
curl -s "http://localhost:9090/api/v1/query?query=ingestion_runs_total" | jq '.data.result | length'
# Doit retourner un nombre > 0 (typiquement 72)

# VÃ©rifier les Ã©checs dÃ©tectÃ©s
curl -s "http://localhost:9090/api/v1/query?query=ingestion_runs_total{etat=\"FAILED\"}" | jq '.data.result | length'
# Doit retourner 1 (EventFactureApplication en FAILED)

# VÃ©rifier les succÃ¨s
curl -s "http://localhost:9090/api/v1/query?query=ingestion_runs_total{etat=\"SUCCESS\"}" | jq '.data.result | length'
# Doit retourner 71
```

2. **VÃ©rifier les durÃ©es d'exÃ©cution**
```bash
curl -s "http://localhost:9090/api/v1/query?query=ingestion_duration_seconds_sum" | jq '.data.result | length'
# Doit retourner le nombre de combinaisons source/objet uniques
```

3. **VÃ©rifier les mÃ©triques de performance**
```bash
# MÃ©triques CPU
curl -s "http://localhost:9090/api/v1/query?query=ingestion_cpu_usage_seconds_sum" | jq '.data.result'

# MÃ©triques MÃ©moire
curl -s "http://localhost:9090/api/v1/query?query=ingestion_memory_usage_bytes_sum" | jq '.data.result'
```

### **Ã‰tape 5 : Test du Dashboard Grafana**

1. **AccÃ©der Ã  Grafana**
```bash
# Ouvrir dans le navigateur
xdg-open http://localhost:3000  # Linux
open http://localhost:3000      # MacOS
start http://localhost:3000     # Windows
```

Identifiants : `admin` / `admin123`

2. **VÃ©rifier le Dashboard**
- Aller dans **Dashboards** > **Dashboard Grafana Ingestion**
- VÃ©rifier que les 5 sections sont prÃ©sentes :
  - Vue d'ensemble --- Ingestion: Health
  - FiabilitÃ© --- Errors & SLAs
  - Performance --- Latency & Throughput
  - DÃ©tails par connecteur --- Sources & Objets
  - Derniers messages d'erreur

3. **VÃ©rifier les donnÃ©es dans les panneaux**
```
- SuccÃ¨s : devrait afficher 71
- Ã‰checs : devrait afficher 1
- Taux d'Ã©chec : devrait afficher ~1.4%
- Sources actives : PowerBI, Efficy, SharePoint, etc.
```

### **Ã‰tape 6 : Test des Alertes**

1. **VÃ©rifier que les rÃ¨gles d'alerte sont chargÃ©es**
```bash
curl -s "http://localhost:9090/api/v1/rules" | jq '.data.groups[].rules[] | select(.type=="alerting") | .name'
```

RÃ©sultat attendu :
```
"IngestionEchecDetecte"
"IngestionTauxEchecEleve"
"IngestionSourceMuette"
"IngestionLatenceDegradee"
"IngestionSurconsommationMemoire"
"IngestionSurconsommationCPU"
"IngestionBurstErreurs"
"IngestionConsumerDown"
"IngestionKafkaLag"
```

2. **VÃ©rifier l'Ã©tat des alertes**
```bash
curl -s "http://localhost:9090/api/v1/alerts" | jq '.data.alerts[] | {alert: .labels.alertname, state: .state}'
```

### **Ã‰tape 7 : Test des Logs dans Loki**

1. **VÃ©rifier que les logs arrivent dans Loki**
```bash
# Query simple
curl -s "http://localhost:3100/loki/api/v1/query?query={job=\"ingestion-logs\"}&limit=5" | jq '.data.result | length'
# Doit retourner > 0

# Query avec filtre sur les Ã©checs
curl -s "http://localhost:3100/loki/api/v1/query?query={job=\"ingestion-logs\"} |= \"FAILED\"&limit=1" | jq '.data.result[0].values[0][1]'
```

### **Ã‰tape 8 : Test de Performance**

1. **Test d'ingestion multiple**
```bash
# ExÃ©cuter le producer plusieurs fois
for i in {1..3}; do
  echo "Run $i"
  docker-compose --profile tools run --rm producer python producer.py
  sleep 10
done
```

2. **VÃ©rifier l'accumulation des mÃ©triques**
```bash
# VÃ©rifier que les totaux augmentent
curl -s "http://localhost:9090/api/v1/query?query=sum(ingestion_runs_total)" | jq '.data.result[0].value[1]'
# Devrait Ãªtre > 144 (72 x 2 runs minimum)
```

### **Ã‰tape 9 : Test des Interfaces de Management**

1. **Kafka UI**
```bash
xdg-open http://localhost:8080  # VÃ©rifier les topics et messages
```

2. **MÃ©triques Consumer directement**
```bash
curl -s http://localhost:8000/metrics | grep ingestion_ | head -10
```

### **Ã‰tape 10 : Test de RÃ©silience**

1. **Tester l'arrÃªt/redÃ©marrage d'un service**
```bash
# ArrÃªter le consumer
docker-compose stop consumer

# Relancer le producer (messages vont s'accumuler dans Kafka)
docker-compose --profile tools run --rm producer python producer.py

# RedÃ©marrer le consumer
docker-compose start consumer

# VÃ©rifier que les messages en attente sont traitÃ©s
docker-compose logs consumer --tail=20
```

2. **VÃ©rifier la rÃ©cupÃ©ration des mÃ©triques**
```bash
# Les mÃ©triques devraient inclure les nouveaux messages
curl -s "http://localhost:9090/api/v1/query?query=sum(ingestion_runs_total)" | jq '.data.result[0].value[1]'
```

## ğŸ” Monitoring et Debugging

### VÃ©rifier les Logs
```bash
# Producer
docker-compose logs -f producer

# Consumer
docker-compose logs -f consumer

# Tous les services
docker-compose logs -f
```

### VÃ©rifier les MÃ©triques
```bash
# MÃ©triques Prometheus du consumer
curl http://localhost:8000/metrics

# Statut Prometheus
curl http://localhost:9090/-/healthy

# Statut Loki
curl http://localhost:3100/ready
```

### Kafka Management
```bash
# Lister les topics
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# DÃ©crire le topic ingestion-logs
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic ingestion-logs

# Consumer group status
docker-compose exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group ingestion-consumer-group
```

## ğŸ§ª Tests et Validation

### Test du Producer
```bash
# ExÃ©cuter le producer une fois
docker-compose run --rm producer python producer.py

# Mode simulation temps rÃ©el
docker-compose run --rm -e SIMULATE_REALTIME=true producer python producer.py
```

### Validation des MÃ©triques
```bash
# VÃ©rifier que les mÃ©triques sont collectÃ©es
curl -s http://localhost:9090/api/v1/query?query=ingestion_runs_total | jq

# VÃ©rifier les logs dans Loki
curl -s "http://localhost:3100/loki/api/v1/query_range?query={job=\"ingestion-logs\"}&start=$(date -d '1 hour ago' --iso-8601)&end=$(date --iso-8601)" | jq
```

### Test des Alertes

1. **Simuler des Ã©checs**: Modifier les logs pour inclure des Ã©tats FAILED
2. **VÃ©rifier dans Grafana**: Aller dans Alerting > Alert Rules
3. **Tester une source muette**: ArrÃªter le producer et attendre 75 minutes

## ğŸ“ Structure du Projet

```
observability-stack/
â”œâ”€â”€ docker-compose.yml              # Configuration Docker Compose
â”œâ”€â”€ logs.json                       # DonnÃ©es d'exemple d'ingestion
â”œâ”€â”€ README.md                       # Documentation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producer/
â”‚   â”‚   â”œâ”€â”€ producer.py             # Script producer Kafka
â”‚   â”‚   â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”‚   â”‚   â””â”€â”€ Dockerfile              # Image Docker producer
â”‚   â””â”€â”€ consumer/
â”‚       â”œâ”€â”€ consumer.py             # Script consumer avec mÃ©triques
â”‚       â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”‚       â””â”€â”€ Dockerfile              # Image Docker consumer
â””â”€â”€ config/
    â”œâ”€â”€ prometheus/
    â”‚   â”œâ”€â”€ prometheus.yml          # Configuration Prometheus
    â”‚   â””â”€â”€ alerts/
    â”‚       â””â”€â”€ ingestion-alerts.yml # RÃ¨gles d'alertes
    â”œâ”€â”€ loki/
    â”‚   â””â”€â”€ loki-config.yml         # Configuration Loki
    â”œâ”€â”€ promtail/
    â”‚   â””â”€â”€ promtail-config.yml     # Configuration Promtail
    â””â”€â”€ grafana/
        â”œâ”€â”€ provisioning/
        â”‚   â”œâ”€â”€ datasources/
        â”‚   â”‚   â””â”€â”€ datasources.yml # Configuration datasources
        â”‚   â””â”€â”€ dashboards/
        â”‚       â””â”€â”€ dashboards.yml  # Configuration dashboards
        â””â”€â”€ dashboards/
            â””â”€â”€ dashboard-grafana-ingestion.json # Dashboard principal
```

## ğŸ”„ Production Readiness

### SÃ©curitÃ©
- [ ] Configurer l'authentification Grafana (LDAP/OAuth)
- [ ] SÃ©curiser Kafka avec SSL/SASL
- [ ] Utiliser des secrets Docker pour les mots de passe
- [ ] Configurer les certificats TLS

### ScalabilitÃ©
- [ ] Augmenter les partitions Kafka pour parallÃ©lisme
- [ ] DÃ©ployer plusieurs instances consumer
- [ ] Configurer la rÃ©plication Kafka
- [ ] Utiliser un stockage persistant (S3, GCS)

### Backup et Recovery
- [ ] Sauvegarder les configurations Grafana
- [ ] Configurer la rÃ©tention des donnÃ©es Prometheus/Loki
- [ ] Planifier les sauvegardes des topics Kafka
- [ ] Documenter les procÃ©dures de recovery

## ğŸ› ï¸ DÃ©pannage

### ProblÃ¨mes Courants

#### Services qui ne dÃ©marrent pas
```bash
# VÃ©rifier les logs
docker-compose logs <service_name>

# RedÃ©marrer un service
docker-compose restart <service_name>

# Reconstruire les images
docker-compose build --no-cache
```

#### Kafka Connection Issues
```bash
# VÃ©rifier la connectivitÃ© Kafka
docker-compose exec producer python -c "from kafka import KafkaProducer; print('OK')"

# VÃ©rifier les topics
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list
```

#### MÃ©triques manquantes
```bash
# VÃ©rifier l'endpoint du consumer
curl http://localhost:8000/metrics

# VÃ©rifier la configuration Prometheus
curl http://localhost:9090/api/v1/targets
```

#### Dashboard vide
1. VÃ©rifier que les datasources sont connectÃ©es
2. VÃ©rifier que les mÃ©triques remontent dans Prometheus
3. VÃ©rifier les labels dans les requÃªtes PromQL

## âœ… RÃ©sultats Attendus des Tests

Si tout fonctionne correctement, vous devriez obtenir :

### MÃ©triques Prometheus
```bash
# Nombre total de mÃ©triques ingestion_runs_total
curl -s "http://localhost:9090/api/v1/query?query=ingestion_runs_total" | jq '.data.result | length'
# RÃ©sultat: 72 (toutes les combinaisons source/objet/Ã©tat)

# Distribution des Ã©tats
curl -s "http://localhost:9090/api/v1/query?query=sum by (etat) (ingestion_runs_total)"
# RÃ©sultat: SUCCESS=71, FAILED=1
```

### Sources de DonnÃ©es IdentifiÃ©es
- **PowerBI**: workspaces, datasets, dashboards, dataflows, etc.
- **Efficy**: Contact, Company, Project, Opportunity, etc.
- **SharePoint**: LignesFacturesApplication, EventFactureApplication, etc.
- **EasyProjects**: Projects, Activities, Users, etc.
- **ZohoBooks**: invoices_ga, invoices_on, items_ga, etc.

### Alertes ConfigurÃ©es
- 9 rÃ¨gles d'alertes chargÃ©es et fonctionnelles
- 1 alerte qui devrait se dÃ©clencher : **IngestionEchecDetecte** (Ã  cause du FAILED)

### Dashboard Grafana
- 5 sections principales avec donnÃ©es
- Visualisations des mÃ©triques de performance
- Table des derniers Ã©checs avec 1 entrÃ©e

### Performance Baseline
- **DurÃ©e moyenne**: ~1-3 secondes par exÃ©cution
- **MÃ©moire moyenne**: 5-20 MB par exÃ©cution
- **CPU moyen**: 0.1-0.5 secondes par exÃ©cution
- **DÃ©bit**: 72 exÃ©cutions en ~1 seconde

## ğŸš€ Commandes Utiles Make

Le projet inclut un Makefile pour simplifier les opÃ©rations :

```bash
# Voir toutes les commandes disponibles
make help

# DÃ©marrer la stack
make up

# VÃ©rifier la santÃ© des services
make health

# IngÃ©rer des donnÃ©es
make ingest

# Voir les mÃ©triques du consumer
make metrics

# Ouvrir les interfaces
make open-grafana
make open-kafka-ui

# Tests automatisÃ©s
make test-stack

# Nettoyage complet
make clean
```

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. Consulter les logs avec `docker-compose logs`
2. VÃ©rifier la documentation des composants
3. Ouvrir une issue avec les logs et la configuration

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.